{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3178d8a2-096c-4f2e-a953-c0c1fd70a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "048bb57c-1742-45b7-a06a-503d6c2e72a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_token_id: 128256\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# tokenizer.model_max_length=1000\n",
    "tokenizer.padding_side='left'\n",
    "tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "pad_token_id = tokenizer.pad_token_id\n",
    "print(f\"pad_token_id: {pad_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "256bddc1-efde-404a-aa69-7dbb773d4ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['instruction', 'input', 'output', 'answer'],\n",
      "        num_rows: 11584\n",
      "    })\n",
      "})\n",
      "{'instruction': \"Classify the following tweet for crisis management. Decide if it gives important information that could help during a crisis. Reply with '1' if the tweet provides useful information, or '0' if it does not. Tweet: RT @Cal_OES: PLS SHARE: Weâ€™re capturing wildfire response, recovery info here: https://t.co/r89LKpjLPj https://t.co/HiA1oQF2Ax.\", 'input': '', 'output': 1, 'answer': 1}\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 11584\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "raw_dataset = load_dataset(\"json\", data_files=\"ft_training_set/digit_train.json\")\n",
    "print(raw_dataset)\n",
    "print(raw_dataset['train'][0])\n",
    "raw_dataset = raw_dataset.rename_column(\"answer\", \"label\")\n",
    "raw_dataset = raw_dataset.rename_column(\"instruction\", \"text\")\n",
    "raw_dataset = raw_dataset.remove_columns(['input', 'output'])\n",
    "print(raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99388238-f5f0-49cb-aa56-639fc3ce0f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_prompt(example):\n",
    "#     return f\"\"\"{example[\"text\"]}\n",
    "# ### Answer:{example[\"answer\"]}\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59bb244b-ec9b-4057-839d-8451e2b3a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    # full_prompt = generate_prompt(example)\n",
    "    # tokenized_full_prompt = tokenizer(full_prompt, truncation=True)\n",
    "    # tokenized_full_prompt['labels'] = tokenized_full_prompt['input_ids'].copy()\n",
    "    return tokenizer(example['text'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dde1a448-f52c-4db4-b427-a32d168a3a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0baa4697387d42799def5a046675ce23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11584 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = raw_dataset.map(tokenize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "817f3816-89a9-4371-874e-58c831b85bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 11584\n",
      "})\n",
      "{'text': \"Classify the following tweet for crisis management. Decide if it gives important information that could help during a crisis. Reply with '1' if the tweet provides useful information, or '0' if it does not. Tweet: RT @Cal_OES: PLS SHARE: Weâ€™re capturing wildfire response, recovery info here: https://t.co/r89LKpjLPj https://t.co/HiA1oQF2Ax.\", 'label': 1, 'input_ids': [128000, 1999, 1463, 279, 2768, 12072, 369, 11501, 6373, 13, 99981, 422, 433, 6835, 3062, 2038, 430, 1436, 1520, 2391, 264, 11501, 13, 18321, 449, 364, 16, 6, 422, 279, 12072, 5825, 5505, 2038, 11, 477, 364, 15, 6, 422, 433, 1587, 539, 13, 26213, 25, 10860, 571, 9027, 2281, 1600, 25, 393, 7416, 54770, 25, 1226, 9011, 48092, 265, 40880, 93225, 2077, 11, 13654, 3630, 1618, 25, 3788, 1129, 83, 6973, 7534, 4578, 94063, 92216, 12852, 73, 3788, 1129, 83, 6973, 14, 13347, 32, 16, 78, 48, 37, 17, 38942, 13], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset['train'])\n",
    "print(tokenized_dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bade7f5-c063-4c60-bc1a-1a5e4eb360d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=8, padding=True)\n",
    "# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "# data_collator = DataCollatorForSeq2Seq(tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fa32975-ad84-40b3-b641-41c95b9fbc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19c019aa-b7a5-47bd-90cb-724363b74c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf9adbac-af3e-4714-8b2a-201c5654c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BitsAndBytesConfig\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_8bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44bbe376-00ea-46ec-ab15-5e945a301683",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"NOT-INFORMATIVE\", 1: \"INFORMATIVE\"}\n",
    "label2id = {\"NOT-INFORMATIVE\": 0, \"INFORMATIVE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84f49bb5-35ad-4c53-98ee-d0bdb78e5107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B-Instruct and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(128257, 2048)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=2, id2label=id2label, label2id=label2id,\n",
    ")\n",
    "model.config.pad_token_id = pad_token_id\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd7add6b-20b5-48c7-9f2d-3ccff17f2bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,904,640 || all params: 1,237,725,184 || trainable%: 0.1539\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=4,\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.1,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"up_proj\", \"down_proj\"],\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(model, lora_config)\n",
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85c669f3-ea05-4802-9d41-f58a8f9140ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir = \"my_awesome_model2\",\n",
    "#     per_device_train_batch_size=8,\n",
    "#     fp16=True,\n",
    "#     use_cpu=True\n",
    "# )\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"my_awesome_model2\",\n",
    "    per_device_train_batch_size=8,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "700251ed-992b-4196-a3c5-89d6c170ca69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongping/miniconda3/envs/LLM_Adapters/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "738121e6-c1ec-42ff-99ec-7c88cf06cf6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4344' max='4344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4344/4344 54:21, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.506800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.440700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.387300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.354400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.361200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.336600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.295600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.285800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4344, training_loss=0.365123123534257, metrics={'train_runtime': 3261.5619, 'train_samples_per_second': 10.655, 'train_steps_per_second': 1.332, 'total_flos': 2.0197395327614976e+16, 'train_loss': 0.365123123534257, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32c4b315-9b9e-4066-bc4c-231ec243f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"my_awesome_model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7063e395-3575-4660-820b-a9ddd8d49cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e1036b-7215-4ce7-a485-00cfbadec11f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
